{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efddfd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 18:12:45.444277: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-04 18:12:45.480924: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-04 18:12:46.026079: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f785dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the input data and targets data Simulated dataset \n",
    "# Example data: LBA, Size, r/w, Sequential\n",
    "data = np.loadtxt('input_data.txt')\n",
    "targets = np.loadtxt('target_data.txt')\n",
    "targets = targets.reshape(-1, 1)\n",
    "full_data = np.concatenate((data, targets), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d6986b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lba = data[:, 0]  # Logical Block Address\n",
    "# size = data[:, 1]  # Size of the I/O request\n",
    "# rw = data[:, 2]  # Read or Write\n",
    "# is_sequential = data[:, 3]  # Is Sequential (1 or 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca15aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Features:\n",
      "[[0.00000000e+00 2.34558249e-03 9.87741832e-03 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [2.98023233e-08 2.34558249e-03 1.48280312e-02 1.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [8.94069698e-08 2.34558249e-03 1.97786441e-02 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " ...\n",
      " [5.00976577e-01 2.34558249e-03 6.54780440e-03 0.00000000e+00\n",
      "  6.37653842e-07]\n",
      " [0.00000000e+00 2.34558249e-03 6.54779450e-03 0.00000000e+00\n",
      "  9.96817470e-01]\n",
      " [0.00000000e+00 9.92963253e-02 6.54780440e-03 0.00000000e+00\n",
      "  6.37653842e-07]]\n"
     ]
    }
   ],
   "source": [
    "# features = np.column_stack((lba, size, rw, is_sequential))\n",
    "# # Apply Min-Max Scaling\n",
    "# scaler = MinMaxScaler()\n",
    "# normalized_features = scaler.fit_transform(features)\n",
    "scaler = MinMaxScaler()\n",
    "normalized_features = scaler.fit_transform(full_data)\n",
    "normalized_data = normalized_features[:, :-1]  # All columns except the last one\n",
    "normalized_targets = normalized_features[:, -1]  # Last column\n",
    "print(\"Normalized Features:\")\n",
    "print(normalized_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a229fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for GRU\n",
    "X = np.expand_dims(normalized_data, axis=0)  # Adding batch dimension\n",
    "y = np.expand_dims(normalized_targets, axis=0)  # Adding batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d44c9f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 18:12:56.858806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22270 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2024-10-04 18:12:56.859323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22061 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Define the GRU model in TensorFlow\n",
    "model = models.Sequential()\n",
    "model.add(layers.GRU(100, return_sequences=True, input_shape=(None, X.shape[2])))\n",
    "model.add(layers.GRU(50, return_sequences=False))\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7355d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83805da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 18:13:09.104858: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2024-10-04 18:13:28.456596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-10-04 18:13:28.499542: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd6d80d8010 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-04 18:13:28.499561: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-10-04 18:13:28.499565: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-10-04 18:13:28.503179: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-04 18:13:28.630804: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 45s 45s/step - loss: 0.0170\n",
      "Epoch 2/250\n",
      "1/1 [==============================] - 42s 42s/step - loss: 6.7303\n",
      "Epoch 3/250\n",
      "1/1 [==============================] - 42s 42s/step - loss: 0.2001\n",
      "Epoch 4/250\n"
     ]
    }
   ],
   "source": [
    "# Train the model (for simplicity, using a few epochs)\n",
    "model.fit(X, y, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7e5688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbba530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the GRU layer weights\n",
    "gru_layer = model.layers[0]\n",
    "weights = gru_layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e80d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights to use them in the C code\n",
    "np.savez('gru_weights.npz', Wz=weights[0], Uz=weights[1], bz=weights[2])\n",
    "print(\"GRU weights saved to 'gru_weights.npz'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d14a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the data (inference)\n",
    "predictions = model.predict(X)\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef69c430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
